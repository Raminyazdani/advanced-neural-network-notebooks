Ramin Yazdani | Advanced Neural Network Regularization Techniques | main | WIP(notebook): Add parameter norm penalties notebook (L1/L2/Elastic Net)

Implemented the first notebook demonstrating classical regularization techniques for linear models using scikit-learn:
- L1 Regularization (Lasso): Encourages sparsity, useful for feature selection
- L2 Regularization (Ridge): Shrinks coefficients to prevent overfitting
- Elastic Net: Combines L1 and L2 penalties for balanced approach

The notebook includes:
- Data loading and preprocessing
- Model training with different regularization strengths
- Visualization of training/validation loss curves
- Comparison of regularized vs unregularized models

NOTE: The data path is set to `regularization_dataset.csv` in the root directory. This should be organized into a data/ subdirectory later.

Verified: parameter_norm_penalties.ipynb created with L1/L2/Elastic Net implementations (path needs correction later).
